import streamlit as st
import streamlit1
import sherbakova
import app
from transformers import AutoTokenizer, AutoModel, pipeline
import torch
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
st.title("–ú–Ω–æ–≥–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ–µ Streamlit-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ")
page = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É", ["–ë–µ–ª–æ–≥–ª–∞–∑–æ–≤–∞", "–£—Å–∞—á—ë–≤–∞", "–©–µ—Ä–±–∞–∫–æ–≤–∞. –¢–∏—Ç–∞–Ω–∏–∫", "–ë–µ–ª–æ–≥–ª–∞–∑–æ–≤–∞. –ù–µ–π—Ä–æ–Ω–∫–∞", "–©–µ—Ä–±–∞–∫–æ–≤–∞. –ù–µ–π—Ä–æ–Ω–∫–∞"])
if page == "–ë–µ–ª–æ–≥–ª–∞–∑–æ–≤–∞":
    streamlit1.show_page()
elif page == "–£—Å–∞—á—ë–≤–∞":
    app.show_page()
elif page == "–©–µ—Ä–±–∞–∫–æ–≤–∞. –¢–∏—Ç–∞–Ω–∏–∫":
    sherbakova.show_page()
elif page == "–ë–µ–ª–æ–≥–ª–∞–∑–æ–≤–∞. –ù–µ–π—Ä–æ–Ω–∫–∞":
    st.title("–ö—Ä–æ—Å—Å-–ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤ (mmBERT)")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ (–æ–¥–∏–Ω —Ä–∞–∑ —á–µ—Ä–µ–∑ Streamlit –∫—ç—à)
    @st.cache_resource
    def load_model():
        tokenizer = AutoTokenizer.from_pretrained("jhu-clsp/mmBERT-base")
        model = AutoModel.from_pretrained("jhu-clsp/mmBERT-base")
        return tokenizer, model
    
    tokenizer, model = load_model()
    def get_embeddings(texts):
        inputs = tokenizer(texts, padding=True, truncation=True, return_tensors="pt", max_length=512)
        with torch.no_grad():
            outputs = model(**inputs)
            # –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É —Å–∫—Ä—ã—Ç–æ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é (–ø–æ —Ç–æ–∫–µ–Ω–∞–º)
            embeddings = outputs.last_hidden_state.mean(dim=1).numpy()
        return embeddings
    
    st.write("–í–≤–µ–¥–∏—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:")
    input_texts = st.text_area(
        "–¢–µ–∫—Å—Ç—ã (–ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫—É)",
        value="""Artificial intelligence is transforming technology\nLa inteligencia artificial est√° transformando la tecnolog√≠a\nL'intelligence artificielle transforme la technologie\n‰∫∫Â∑•Êô∫ËÉΩÊ≠£Âú®ÊîπÂèòÊäÄÊúØ""",
        height=150
    )
    
    show_matrix = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–ª–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É —Å—Ö–æ–∂–µ—Å—Ç–∏", True)
    
    if st.button("–í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ö–æ–∂–µ—Å—Ç—å"):
        if not input_texts.strip():
            st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ.")
        else:
            texts = [line.strip() for line in input_texts.split("\n") if line.strip()]
            
            if len(texts) < 2:
                st.warning("–í–≤–µ–¥–∏—Ç–µ —Ö–æ—Ç—è –±—ã –¥–≤–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.")
            else:
                with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤..."):
                    try:
                        embeddings = get_embeddings(texts)
                        similarities = cosine_similarity(embeddings)
    
                        st.success("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    
                        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                        st.write("### –ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏:")
                        if show_matrix:
                            st.dataframe(similarities.round(4))
                        else:
                            st.write("–ü–æ–∫–∞–∑–∞–Ω—ã —Ç–æ–ª—å–∫–æ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Å –ø–µ—Ä–≤—ã–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º:")
                            first_similarities = similarities[0].round(4)
                            sim_table = {
                                "–¢–µ–∫—Å—Ç": texts,
                                "–°—Ö–æ–∂–µ—Å—Ç—å —Å –ø–µ—Ä–≤—ã–º": first_similarities
                            }
                            st.table(sim_table)
    
                        # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã
                        if st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–ø–ª–æ–≤—É—é –∫–∞—Ä—Ç—É"):
                            import seaborn as sns
                            import matplotlib.pyplot as plt
                            fig, ax = plt.subplots(figsize=(6, 5))
                            sns.heatmap(similarities, annot=True, xticklabels=[t[:10] + "..." for t in texts],
                                        yticklabels=[t[:10] + "..." for t in texts], cmap='Blues', ax=ax)
                            plt.title("–ö–æ—Å–∏–Ω—É—Å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å (—ç–º–±–µ–¥–¥–∏–Ω–≥–∏ mmBERT)")
                            st.pyplot(fig)
    
                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {str(e)}")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
    with st.expander("‚ÑπÔ∏è –û –º–æ–¥–µ–ª–∏ mmBERT"):
        st.markdown("""
        –ú–æ–¥–µ–ª—å **jhu-clsp/mmBERT-base** ‚Äî —ç—Ç–æ –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω–∞—è BERT-–º–æ–¥–µ–ª—å, –æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∫–æ—Ä–ø—É—Å–∞—Ö –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫—Ä–æ—Å—Å-–ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π.
        –û–Ω–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö.
        """)
elif page == "–©–µ—Ä–±–∞–∫–æ–≤–∞. –ù–µ–π—Ä–æ–Ω–∫–∞":
    st.title("–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Å–ø–∞–º")

    @st.cache_resource
    def load_spam_model():
        try:
            with st.spinner("–ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å RUSpam/spam_deberta_v4... –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ."):
                model = pipeline("text-classification", model="RUSpam/spam_deberta_v4")
            return model
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")
            st.stop()

    textclassification = load_spam_model()
    st.success("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!")

    text = st.text_area("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:", "–í—ã –≤—ã–∏–≥—Ä–∞–ª–∏ –ø—Ä–∏–∑! –ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –ø–æ —Å—Å—ã–ª–∫–µ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è")

    if st.button("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å"):
        if not text.strip():
            st.warning("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
        else:
            with st.spinner("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ç–µ–∫—Å—Ç..."):
                result = textclassification(text)[0]
                label = result["label"]
                score = result["score"]
                verdict = "–°–ø–∞–º" if label == "LABEL_1" else "–ù–µ —Å–ø–∞–º"

            st.subheader(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: **{verdict}**")
            st.progress(score)
            st.write(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: {score*100:.2f}%")
